# Natural Language Processing (NLP) Project

This repository contains a comprehensive collection of NLP techniques and implementations, ranging from basic text processing to advanced machine learning applications.

## ğŸ“ Project Structure

```
NLP/
â”œâ”€â”€ README.md
â”œâ”€â”€ download_nltk_data.py
â”œâ”€â”€ tokenization.py
â”œâ”€â”€ stemming.py
â”œâ”€â”€ lemmatization.py
â”œâ”€â”€ bag_of_words.py
â”œâ”€â”€ TF_IDF.py
â”œâ”€â”€ word2vec.py
â”œâ”€â”€ Pos_tagging.py
â”œâ”€â”€ NER.py
â””â”€â”€ projects/
    â””â”€â”€ spam_classifier/
        â”œâ”€â”€ spam_classifier.py
        â””â”€â”€ data/
            â””â”€â”€ SMSSpamCollection.txt
```

## ğŸš€ Getting Started

### Prerequisites

Before running the scripts, make sure you have the following packages installed:

```bash
pip install nltk spacy scikit-learn pandas numpy gensim
```

### Setup

1. **Download NLTK Data**: Run the setup script to download required NLTK data:
   ```bash
   python download_nltk_data.py
   ```

2. **Install spaCy Model**: Download the English language model for spaCy:
   ```bash
   python -m spacy download en_core_web_sm
   ```

## ğŸ“š Modules Overview

### 1. Text Preprocessing

#### `tokenization.py`
- **Purpose**: Demonstrates sentence and word tokenization using NLTK
- **Features**: 
  - Sentence tokenization
  - Word tokenization
  - Token counting
- **Usage**: 
  ```bash
  python tokenization.py
  ```

#### `stemming.py`
- **Purpose**: Implements Porter Stemmer for word stemming
- **Features**:
  - Porter Stemmer implementation
  - Word normalization
- **Usage**:
  ```bash
  python stemming.py
  ```

#### `lemmatization.py`
- **Purpose**: Demonstrates lemmatization using WordNet
- **Features**:
  - WordNet Lemmatizer
  - Part-of-speech aware lemmatization
- **Usage**:
  ```bash
  python lemmatization.py
  ```

### 2. Feature Extraction

#### `bag_of_words.py`
- **Purpose**: Implements Bag of Words (BoW) feature extraction
- **Features**:
  - Text preprocessing (cleaning, lowercase, stopword removal)
  - Lemmatization
  - CountVectorizer implementation
- **Usage**:
  ```bash
  python bag_of_words.py
  ```

#### `TF_IDF.py`
- **Purpose**: Implements TF-IDF (Term Frequency-Inverse Document Frequency) feature extraction
- **Features**:
  - TF-IDF vectorization
  - Text preprocessing pipeline
- **Usage**:
  ```bash
  python TF_IDF.py
  ```

#### `word2vec.py`
- **Purpose**: Implements Word2Vec for word embeddings
- **Features**:
  - Word2Vec model training
  - Text preprocessing for embeddings
  - Vocabulary extraction
- **Usage**:
  ```bash
  python word2vec.py
  ```

### 3. Linguistic Analysis

#### `Pos_tagging.py`
- **Purpose**: Demonstrates Part-of-Speech (POS) tagging using spaCy
- **Features**:
  - POS tagging
  - Detailed token analysis
  - POS explanations
- **Usage**:
  ```bash
  python Pos_tagging.py
  ```

#### `NER.py`
- **Purpose**: Implements Named Entity Recognition (NER) using spaCy
- **Features**:
  - Named entity detection
  - Entity type classification
  - Detailed token analysis
  - Entity explanations
- **Usage**:
  ```bash
  python NER.py
  ```

## ğŸ¤– Machine Learning Projects

### Spam Classifier (`projects/spam_classifier/`)

A complete spam detection system using machine learning techniques.

#### Features:
- **Dataset**: SMS Spam Collection Dataset
- **Preprocessing**: Text cleaning, lemmatization, stopword removal
- **Feature Extraction**: Bag of Words with CountVectorizer
- **Model**: Multinomial Naive Bayes
- **Evaluation**: Confusion matrix and accuracy metrics

#### Usage:
```bash
cd projects/spam_classifier
python spam_classifier.py
```

#### Dataset:
The spam classifier uses the SMS Spam Collection Dataset located in `projects/spam_classifier/data/SMSSpamCollection.txt`.

## ğŸ”§ Key Technologies Used

- **NLTK**: Natural Language Toolkit for text processing
- **spaCy**: Advanced NLP library for linguistic analysis
- **scikit-learn**: Machine learning library for feature extraction and modeling
- **pandas**: Data manipulation and analysis
- **gensim**: Word embeddings and topic modeling
- **NumPy**: Numerical computing

## ğŸ“Š Output Examples

### Tokenization Output:
```
['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'field', 'of', 'artificial', 'intelligence', ...]
len of words 45
```

### POS Tagging Output:
```
Elon ! PROPN NNP proper noun
flew ! VERB VBD verb, past tense
to ! ADP IN adposition
Mars ! PROPN NNP proper noun
yesterday ! NOUN NN noun, singular or mass
```

### NER Output:
```
Entity Text | Label | Description
John Doe    | PERSON| People, including fictional
New York City| GPE  | Countries, cities, states
Google      | ORG  | Companies, agencies, institutions
```

## ğŸ¤ Contributing

Feel free to contribute to this project by:
1. Adding new NLP techniques
2. Improving existing implementations
3. Adding more machine learning projects
4. Enhancing documentation

## ğŸ“ License

This project is open source and available under the [MIT License](LICENSE).

## ğŸ“ Contact

For questions or suggestions, please open an issue in the repository.

---

**Note**: Make sure to run `download_nltk_data.py` first to download all required NLTK data before running other scripts.
